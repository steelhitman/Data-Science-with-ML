{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, LabelBinarizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from numpy import absolute\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras import Sequential\n",
    "import keras\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = pd.read_csv('Training_values.csv')\n",
    "labels = pd.read_csv('Training_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([labels,values], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:,~df.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "33 categorical 4 continuous\n",
    "\n",
    "date_recorded  -  object\n",
    "funder  -  object\n",
    "installer  -  object\n",
    "wpt_name  -  object\n",
    "num_private  -  int64\n",
    "basin  -  object\n",
    "subvillage  -  object\n",
    "region  -  object\n",
    "region_code  -  int64\n",
    "district_code  -  int64\n",
    "lga  -  object\n",
    "ward  -  object\n",
    "public_meeting  -  object\n",
    "recorded_by  -  object\n",
    "scheme_management  -  object\n",
    "scheme_name  -  object\n",
    "permit  -  object\n",
    "construction_year  -  int64\n",
    "extraction_type  -  object\n",
    "extraction_type_group  -  object\n",
    "extraction_type_class  -  object\n",
    "management  -  object\n",
    "management_group  -  object\n",
    "payment  -  object\n",
    "payment_type  -  object\n",
    "water_quality  -  object\n",
    "quality_group  -  object\n",
    "quantity  -  object\n",
    "quantity_group  -  object\n",
    "source  -  object\n",
    "source_type  -  object\n",
    "source_class  -  object\n",
    "waterpoint_type  -  object\n",
    "waterpoint_type_group  -  object\n",
    "status_group  -  object\n",
    "\n",
    "id  -  int64\n",
    "amount_tsh  -  float64\n",
    "longitude  -  float64\n",
    "latitude  -  float64\n",
    "population  -  int64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df):\n",
    "    print(\"Preprocessing Data\")\n",
    "    df = df.drop_duplicates()\n",
    "    #for column in df.columns:\n",
    "    #    print(column,\" - \", df[column].dtype)\n",
    "    df.isna().sum()\n",
    "    #df.dropna(inplace=True)\n",
    "    df.isna().sum()\n",
    "\n",
    "    drop_columns = [\"id\", \"date_recorded\", \"funder\", \"installer\", \"longitude\",\n",
    "                    \"latitude\", \"wpt_name\", \"region\", \"region_code\",\n",
    "                    \"district_code\", \"lga\", \"ward\", \"recorded_by\",\n",
    "                    \"scheme_management\", \"scheme_name\", \"construction_year\", \"extraction_type\",\n",
    "                    \"extraction_type_group\", \"extraction_type_class\", \"management\", \"management_group\",\n",
    "                    \"payment\", \"payment_type\", \"waterpoint_type\", \"waterpoint_type_group\", \"subvillage\"]\n",
    "\n",
    "\n",
    "    df.drop(drop_columns, inplace=True, axis=1)\n",
    "    df.drop('num_private', inplace=True, axis=1)\n",
    "    \n",
    "    #for columns in df.columns:\n",
    "    #    print(columns, \" - \", df[columns].dtype)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_fill(df):\n",
    "    print(\"Using Forward Fill to handle missing data\")\n",
    "    return df.ffill(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_fill(df):\n",
    "    print(\"Using Backward Fill to handle missing data\")\n",
    "    return df.bfill(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simpleImputer(df):\n",
    "    print(\"Using Simple Imputer to handle missing data\")\n",
    "\n",
    "    imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent', add_indicator=True)\n",
    "\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == 'object':\n",
    "            df[column] = imputer.fit_transform(df[column].values.reshape(-1, 1))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KnnImputer(df):\n",
    "    print(\"Using KNN Imputer to handle missing data\")\n",
    "    imputer = KNNImputer(missing_values=np.nan,n_neighbors=5, add_indicator=True)\n",
    "    for column in df.columns:\n",
    "        df[column] = imputer.fit_transform(df[column].values.reshape(-1, 1))\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualisation(df):\n",
    "    print(\"Visualising data\")\n",
    "    df.plot(kind='box', subplots = True, layout = (24,5), figsize = (30,40))\n",
    "    \n",
    "    df.plot(kind='scatter', subplots=True, layout=(24, 5), figsize=(30, 40))\n",
    "    \n",
    "    df = df.drop(df[(np.absolute(df['latitude']) <= 1) &\n",
    "                 (np.absolute(df['longitude']) <= 1)].index)\n",
    "    \n",
    "    map_img = plt.imread('map.jpg')\n",
    "\n",
    "\n",
    "    plot = sns.scatterplot(data=df, y='longitude', x='latitude',\n",
    "                        hue='status_group', palette='colorblind', alpha=0.6, zorder=2)\n",
    "\n",
    "    plot.imshow(map_img,\n",
    "                aspect=plot.get_aspect(),\n",
    "                extent=plot.get_xlim() + plot.get_ylim(),\n",
    "                zorder=1)\n",
    "\n",
    "    sns.countplot(data = df, x = 'status_group')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneHotEncoding(df):\n",
    "    print(\"Using Binary Encoding to handle string Data\")\n",
    "    \n",
    "    df_new = df.copy()\n",
    "\n",
    "    encoder = LabelEncoder()\n",
    "    df_new['status_group'] = encoder.fit_transform(df['status_group'].values)\n",
    "    y = np_utils.to_categorical(df_new['status_group'])\n",
    "    \n",
    "    oneHot = OneHotEncoder(categories='auto', sparse=False, dtype=int, handle_unknown='ignore')\n",
    "    columns = []\n",
    "    for column in df.columns:\n",
    "        if str(df_new[column].dtype) == \"object\":\n",
    "            columns.append(column)\n",
    "\n",
    "    print(columns)\n",
    "        \n",
    "    oneHot_encoded = pd.DataFrame(oneHot.fit_transform(df_new[columns]), index=df_new.index, columns=oneHot.get_feature_names(df_new[columns].columns))\n",
    "    df_new.drop(columns, inplace = True, axis = 1)\n",
    "    df_new = pd.concat([df_new,oneHot_encoded], axis = 1)\n",
    "    \n",
    "    return df_new, y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelEncoding(df):\n",
    "    print(\"Using Label Encoder to handle string data\")\n",
    "\n",
    "    encoder_1 = LabelEncoder()\n",
    "    label_columns = ['quantity_group', 'quality_group']\n",
    "\n",
    "    df_new = df.copy()\n",
    "\n",
    "    labels = {}\n",
    "\n",
    "    for column in df.columns:\n",
    "        if column in label_columns:\n",
    "            df_new[column] = encoder_1.fit_transform(df[column].values)\n",
    "            labels[column] = encoder_1.classes_\n",
    "\n",
    "    graph = sns.barplot(data=df_new, x='quantity_group',\n",
    "                        y='quality_group', hue='status_group')\n",
    "    graph.set_xticklabels(labels['quantity_group'])\n",
    "    graph.set_yticklabels(labels['quality_group'])\n",
    "\n",
    "    encoder = LabelEncoder()\n",
    "    #label_columns = ['basin','public_health','permit','water_quality','quantity','quantity_group','quality','quality_group','source','source_type','source_class']\n",
    "\n",
    "    df['status_group'] = encoder.fit_transform(df['status_group'].values)\n",
    "    y = np_utils.to_categorical(df['status_group'])\n",
    "\n",
    "    for column in df.columns:\n",
    "        if str(df[column].dtype) == \"object\":\n",
    "            df[column] = encoder.fit_transform(df[column].values)\n",
    "    \n",
    "    df.head(10)\n",
    "    \n",
    "    return df, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap_pearson(df):\n",
    "    sns.heatmap(df.corr('pearson'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap_spearman(df):\n",
    "    sns.heatmap(df.corr('spearman'), cmap='crest')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.heatmap(data=df_new, x='quantity_group', y='quality_group', hue='status_group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minMaxScaler(df):\n",
    "    print(\"Using Min Max Scaler to Normalise the continuous data\")\n",
    "\n",
    "    normalize_columns = [\"amount_tsh\", \"gps_height\", \"population\"]\n",
    "\n",
    "    for column in normalize_columns:\n",
    "        df[column] = (df[column] - min(df[column])) / (max(df[column]) - min(df[column]))\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardScaler(df):\n",
    "    print(\"Using Standard Scaler to standardise the data\")\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    normalize_columns = [\"amount_tsh\", \"gps_height\", \"population\"]\n",
    "    \n",
    "    scaled_df = scaler.fit_transform(df[normalize_columns].to_numpy())\n",
    "    scaled_df = pd.DataFrame(scaled_df, columns=normalize_columns, index= df.index)\n",
    "    df = df.drop(normalize_columns, axis = 1)\n",
    "    df = pd.concat([df, scaled_df], axis=1)  \n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection_correlation(df):\n",
    "    print(\"Using Pearson Correlation for feature selection\")\n",
    "    \n",
    "    sns.heatmap(df.corr('pearson'))\n",
    "\n",
    "    correlations = df.corr('pearson')\n",
    "\n",
    "    corr_df = correlations[-1:]\n",
    "\n",
    "    print(corr_df)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(120, 1))\n",
    "    sns.heatmap(corr_df, annot=True, ax=ax)\n",
    "    \n",
    "    threshold = 0.01\n",
    "\n",
    "    columns = list(corr_df.columns.values)\n",
    "    row = corr_df.iloc[0]\n",
    "\n",
    "    #test_columns = []\n",
    "\n",
    "    #for column in columns:\n",
    "    #    if absolute(corr_df.iloc[0][column]) < threshold:\n",
    "    #        df.drop([column], axis=1, inplace=True)\n",
    "    #    else:\n",
    "    #        test_columns.append(column)\n",
    "    #print(test_columns)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection_importance(df):\n",
    "    print(\"Using Random Forest for feature importance\")\n",
    "\n",
    "    X = df.drop('status_group', axis=1)\n",
    "    y = df['status_group']\n",
    "\n",
    "    feature_names = [f\"feature {i}\" for i in range(X.shape[1])]\n",
    "    forest = RandomForestClassifier(random_state=0)\n",
    "    forest.fit(X, y)\n",
    "    \n",
    "    importances = forest.feature_importances_\n",
    "    print(importances)\n",
    "    print(feature_names)    \n",
    "    threshold = 0.01\n",
    "\n",
    "    columns = list(corr_df.columns.values)\n",
    "    row = corr_df.iloc[0]\n",
    "\n",
    "    #test_columns = []\n",
    "\n",
    "    #for column in columns:\n",
    "    #    if absolute(corr_df.iloc[0][column]) < threshold:\n",
    "    #        df.drop([column], axis=1, inplace=True)\n",
    "    #    else:\n",
    "    #        test_columns.append(column)\n",
    "    #print(test_columns)\n",
    "\n",
    "    return df\n",
    "\n",
    "#feature_selection_importance(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_feature_selection(df):\n",
    "    X = df.drop('status_group', axis=1)\n",
    "    y = df['status_group']\n",
    "    for i in range(1,len(X.columns)+1):\n",
    "        rfe = RFE(DecisionTreeClassifier(), n_features_to_select = i)\n",
    "        model = xgb.XGBClassifier(objective='multi:softprob')\n",
    "        pipeline = Pipeline(steps = [('s', rfe),('m', model)])\n",
    "        cv = RepeatedStratifiedKFold(n_splits = 10, n_repeats=3 , random_state= 2)\n",
    "        n_scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv = cv, n_jobs = -1, error_score='raise')\n",
    "        print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing Data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount_tsh</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>basin</th>\n",
       "      <th>population</th>\n",
       "      <th>public_meeting</th>\n",
       "      <th>permit</th>\n",
       "      <th>water_quality</th>\n",
       "      <th>quality_group</th>\n",
       "      <th>quantity</th>\n",
       "      <th>quantity_group</th>\n",
       "      <th>source</th>\n",
       "      <th>source_type</th>\n",
       "      <th>source_class</th>\n",
       "      <th>status_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6000.0</td>\n",
       "      <td>1390</td>\n",
       "      <td>Lake Nyasa</td>\n",
       "      <td>109</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>enough</td>\n",
       "      <td>enough</td>\n",
       "      <td>spring</td>\n",
       "      <td>spring</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1399</td>\n",
       "      <td>Lake Victoria</td>\n",
       "      <td>280</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>surface</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.0</td>\n",
       "      <td>686</td>\n",
       "      <td>Pangani</td>\n",
       "      <td>250</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>enough</td>\n",
       "      <td>enough</td>\n",
       "      <td>dam</td>\n",
       "      <td>dam</td>\n",
       "      <td>surface</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>263</td>\n",
       "      <td>Ruvuma / Southern Coast</td>\n",
       "      <td>58</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>dry</td>\n",
       "      <td>dry</td>\n",
       "      <td>machine dbh</td>\n",
       "      <td>borehole</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Lake Victoria</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>seasonal</td>\n",
       "      <td>seasonal</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>surface</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Pangani</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>salty</td>\n",
       "      <td>salty</td>\n",
       "      <td>enough</td>\n",
       "      <td>enough</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>unknown</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Internal</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>enough</td>\n",
       "      <td>enough</td>\n",
       "      <td>machine dbh</td>\n",
       "      <td>borehole</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Lake Tanganyika</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>milky</td>\n",
       "      <td>milky</td>\n",
       "      <td>enough</td>\n",
       "      <td>enough</td>\n",
       "      <td>shallow well</td>\n",
       "      <td>shallow well</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Lake Tanganyika</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>salty</td>\n",
       "      <td>salty</td>\n",
       "      <td>seasonal</td>\n",
       "      <td>seasonal</td>\n",
       "      <td>machine dbh</td>\n",
       "      <td>borehole</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Lake Victoria</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>enough</td>\n",
       "      <td>enough</td>\n",
       "      <td>shallow well</td>\n",
       "      <td>shallow well</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   amount_tsh  gps_height                    basin  population public_meeting  \\\n",
       "0      6000.0        1390               Lake Nyasa         109           True   \n",
       "1         0.0        1399            Lake Victoria         280            NaN   \n",
       "2        25.0         686                  Pangani         250           True   \n",
       "3         0.0         263  Ruvuma / Southern Coast          58           True   \n",
       "4         0.0           0            Lake Victoria           0           True   \n",
       "5        20.0           0                  Pangani           1           True   \n",
       "6         0.0           0                 Internal           0           True   \n",
       "7         0.0           0          Lake Tanganyika           0           True   \n",
       "8         0.0           0          Lake Tanganyika           0           True   \n",
       "9         0.0           0            Lake Victoria           0           True   \n",
       "\n",
       "  permit water_quality quality_group      quantity quantity_group  \\\n",
       "0  False          soft          good        enough         enough   \n",
       "1   True          soft          good  insufficient   insufficient   \n",
       "2   True          soft          good        enough         enough   \n",
       "3   True          soft          good           dry            dry   \n",
       "4   True          soft          good      seasonal       seasonal   \n",
       "5   True         salty         salty        enough         enough   \n",
       "6   True          soft          good        enough         enough   \n",
       "7   True         milky         milky        enough         enough   \n",
       "8   True         salty         salty      seasonal       seasonal   \n",
       "9   True          soft          good        enough         enough   \n",
       "\n",
       "                 source           source_type source_class    status_group  \n",
       "0                spring                spring  groundwater      functional  \n",
       "1  rainwater harvesting  rainwater harvesting      surface      functional  \n",
       "2                   dam                   dam      surface      functional  \n",
       "3           machine dbh              borehole  groundwater  non functional  \n",
       "4  rainwater harvesting  rainwater harvesting      surface      functional  \n",
       "5                 other                 other      unknown      functional  \n",
       "6           machine dbh              borehole  groundwater  non functional  \n",
       "7          shallow well          shallow well  groundwater  non functional  \n",
       "8           machine dbh              borehole  groundwater  non functional  \n",
       "9          shallow well          shallow well  groundwater      functional  "
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = preprocessing(df)\n",
    "df_new.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Binary Encoding to handle string Data\n",
      "['basin', 'public_meeting', 'permit', 'water_quality', 'quality_group', 'quantity', 'quantity_group', 'source', 'source_type', 'source_class']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prash\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "df_test,y = oneHotEncoding(df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount_tsh</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>population</th>\n",
       "      <th>status_group</th>\n",
       "      <th>basin_Internal</th>\n",
       "      <th>basin_Lake Nyasa</th>\n",
       "      <th>basin_Lake Rukwa</th>\n",
       "      <th>basin_Lake Tanganyika</th>\n",
       "      <th>basin_Lake Victoria</th>\n",
       "      <th>basin_Pangani</th>\n",
       "      <th>...</th>\n",
       "      <th>source_type_borehole</th>\n",
       "      <th>source_type_dam</th>\n",
       "      <th>source_type_other</th>\n",
       "      <th>source_type_rainwater harvesting</th>\n",
       "      <th>source_type_river/lake</th>\n",
       "      <th>source_type_shallow well</th>\n",
       "      <th>source_type_spring</th>\n",
       "      <th>source_class_groundwater</th>\n",
       "      <th>source_class_surface</th>\n",
       "      <th>source_class_unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6000.0</td>\n",
       "      <td>1390</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1399</td>\n",
       "      <td>280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.0</td>\n",
       "      <td>686</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>263</td>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   amount_tsh  gps_height  population  status_group  basin_Internal  \\\n",
       "0      6000.0        1390         109             0               0   \n",
       "1         0.0        1399         280             0               0   \n",
       "2        25.0         686         250             0               0   \n",
       "3         0.0         263          58             2               0   \n",
       "4         0.0           0           0             0               0   \n",
       "\n",
       "   basin_Lake Nyasa  basin_Lake Rukwa  basin_Lake Tanganyika  \\\n",
       "0                 1                 0                      0   \n",
       "1                 0                 0                      0   \n",
       "2                 0                 0                      0   \n",
       "3                 0                 0                      0   \n",
       "4                 0                 0                      0   \n",
       "\n",
       "   basin_Lake Victoria  basin_Pangani  ...  source_type_borehole  \\\n",
       "0                    0              0  ...                     0   \n",
       "1                    1              0  ...                     0   \n",
       "2                    0              1  ...                     0   \n",
       "3                    0              0  ...                     1   \n",
       "4                    1              0  ...                     0   \n",
       "\n",
       "   source_type_dam  source_type_other  source_type_rainwater harvesting  \\\n",
       "0                0                  0                                 0   \n",
       "1                0                  0                                 1   \n",
       "2                1                  0                                 0   \n",
       "3                0                  0                                 0   \n",
       "4                0                  0                                 1   \n",
       "\n",
       "   source_type_river/lake  source_type_shallow well  source_type_spring  \\\n",
       "0                       0                         0                   1   \n",
       "1                       0                         0                   0   \n",
       "2                       0                         0                   0   \n",
       "3                       0                         0                   0   \n",
       "4                       0                         0                   0   \n",
       "\n",
       "   source_class_groundwater  source_class_surface  source_class_unknown  \n",
       "0                         1                     0                     0  \n",
       "1                         0                     1                     0  \n",
       "2                         0                     1                     0  \n",
       "3                         1                     0                     0  \n",
       "4                         0                     1                     0  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['amount_tsh', 'gps_height', 'population', 'status_group',\n",
       "       'basin_Internal', 'basin_Lake Nyasa', 'basin_Lake Rukwa',\n",
       "       'basin_Lake Tanganyika', 'basin_Lake Victoria', 'basin_Pangani',\n",
       "       'basin_Rufiji', 'basin_Ruvuma / Southern Coast', 'basin_Wami / Ruvu',\n",
       "       'public_meeting_False', 'public_meeting_True', 'public_meeting_nan',\n",
       "       'permit_False', 'permit_True', 'permit_nan', 'water_quality_coloured',\n",
       "       'water_quality_fluoride', 'water_quality_fluoride abandoned',\n",
       "       'water_quality_milky', 'water_quality_salty',\n",
       "       'water_quality_salty abandoned', 'water_quality_soft',\n",
       "       'water_quality_unknown', 'quality_group_colored',\n",
       "       'quality_group_fluoride', 'quality_group_good', 'quality_group_milky',\n",
       "       'quality_group_salty', 'quality_group_unknown', 'quantity_dry',\n",
       "       'quantity_enough', 'quantity_insufficient', 'quantity_seasonal',\n",
       "       'quantity_unknown', 'quantity_group_dry', 'quantity_group_enough',\n",
       "       'quantity_group_insufficient', 'quantity_group_seasonal',\n",
       "       'quantity_group_unknown', 'source_dam', 'source_hand dtw',\n",
       "       'source_lake', 'source_machine dbh', 'source_other',\n",
       "       'source_rainwater harvesting', 'source_river', 'source_shallow well',\n",
       "       'source_spring', 'source_unknown', 'source_type_borehole',\n",
       "       'source_type_dam', 'source_type_other',\n",
       "       'source_type_rainwater harvesting', 'source_type_river/lake',\n",
       "       'source_type_shallow well', 'source_type_spring',\n",
       "       'source_class_groundwater', 'source_class_surface',\n",
       "       'source_class_unknown'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using KNN Imputer to handle missing data\n"
     ]
    }
   ],
   "source": [
    "df_test = KnnImputer(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.675 (0.005)\n"
     ]
    }
   ],
   "source": [
    "recursive_feature_selection(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequential_model(X_train, X_test, y_train, y_test):\n",
    "    print(\"Sequential Model\")\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1000, activation='sigmoid', input_shape=(X_train.shape[1],)))\n",
    "    model.add(Dense(500, activation='sigmoid'))\n",
    "    model.add(Dense(250, activation='sigmoid'))\n",
    "    model.add(Dense(200, activation='sigmoid'))\n",
    "    model.add(Dense(100, activation='sigmoid'))\n",
    "    model.add(Dense(50, activation='sigmoid'))\n",
    "    model.add(Dense(25, activation='sigmoid'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "    es = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                    mode='min',\n",
    "                                    patience=10,\n",
    "                                    restore_best_weights=True)\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(X_train, y_train, batch_size=128, epochs=500, shuffle=True, verbose=2)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    for y in y_pred:\n",
    "        for i in range(len(y)):\n",
    "            if y[i] > 0.5:\n",
    "                y[i] = 1\n",
    "            else:\n",
    "                y[i] = 0\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XGBoost(X_train, X_test, y_train, y_test):\n",
    "    print(\"XGBoost Model\")\n",
    "    model = xgb.XGBClassifier(objective = 'multi:softprob', random_state = 1, n_estimators = 200, max_depth = 5)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(y_pred)\n",
    "    \n",
    "    return y_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdaBoost(X_train, X_test, y_train, y_test):\n",
    "    print(\"ADABoost Model\")\n",
    "    parameters = {\n",
    "        'n_estimators':[i for i in range(100,1000,100)],\n",
    "        'learning_rate':[i*0.1 for i in range(1,10,1)]\n",
    "    }\n",
    "    model = AdaBoostClassifier(random_state=0)\n",
    "    ada = GridSearchCV(model, parameters)\n",
    "    ada.fit(X_train, y_train)\n",
    "    y_pred = ada.predict(X_test)\n",
    "    print(y_pred)\n",
    "    print(ada.cv_results_)\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GradientBoost(X_train, X_test, y_train, y_test):\n",
    "    print(\"Gradient Boost Model\")\n",
    "    parameters = {\n",
    "        'n_estimators': [i for i in range(100, 1000, 100)],\n",
    "        'learning_rate': [i*0.1 for i in range(1, 10, 1)],\n",
    "        'criterion': ['friedman_mse', 'squared_error']\n",
    "    }\n",
    "    model = GradientBoostingClassifier()\n",
    "    gb = GridSearchCV(model, parameters)\n",
    "    gb.fit(X_train, y_train)\n",
    "    y_pred = gb.predict(X_test)\n",
    "    print(y_pred)\n",
    "    print(gb.cv_results_)\n",
    "\n",
    "    return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Report(y_test, y_pred):\n",
    "    print(\"Generating Report\")\n",
    "    from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "    labels = ['0', '1', '2']\n",
    "\n",
    "    report = classification_report(y_test, y_pred, target_names=labels)\n",
    "\n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualisation(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Approach_1(df):\n",
    "    df = preprocessing(df)\n",
    "    df = simpleImputer(df)\n",
    "    df, y = labelEncoding(df)\n",
    "    df = minMaxScaler(df)\n",
    "    df = feature_selection_correlation(df)\n",
    "    \n",
    "    X = df.drop('status_group', axis=1)\n",
    "    y = df['status_group']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = True)\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "    print(X_train.shape)\n",
    "    print(y_train.shape)\n",
    "    print(X_test.shape)\n",
    "    print(y_test.shape)\n",
    "    y_pred = XGBoost(X_train, X_test, y_train, y_test)\n",
    "    report = Report(y_test, y_pred)\n",
    "    print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Approach_2(df):\n",
    "    df = preprocessing(df)\n",
    "    df = simpleImputer(df)\n",
    "    df, y = labelEncoding(df)\n",
    "    df = minMaxScaler(df)\n",
    "    df = feature_selection_correlation(df)\n",
    "\n",
    "    X = df.drop('status_group', axis=1)\n",
    "    y = df['status_group']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "    print(X_train.shape)\n",
    "    print(y_train.shape)\n",
    "    print(X_test.shape)\n",
    "    print(y_test.shape)\n",
    "    y_pred = AdaBoost(X_train, X_test, y_train, y_test)\n",
    "    report = Report(y_test, y_pred)\n",
    "    print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Approach_3(df):\n",
    "    df = preprocessing(df)\n",
    "    df = simpleImputer(df)\n",
    "    df, y = labelEncoding(df)\n",
    "    df = minMaxScaler(df)\n",
    "    df = feature_selection_correlation(df)\n",
    "\n",
    "    X = df.drop('status_group', axis=1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "    print(X_train.shape)\n",
    "    print(y_train.shape)\n",
    "    print(X_test.shape)\n",
    "    print(y_test.shape)\n",
    "    y_pred = sequential_model(X_train, X_test, y_train, y_test)\n",
    "    report = Report(y_test, y_pred)\n",
    "    print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Approach_4(df):\n",
    "    df = preprocessing(df)\n",
    "    df = simpleImputer(df)\n",
    "    df, y = labelEncoding(df)\n",
    "    df = minMaxScaler(df)\n",
    "    df = feature_selection_correlation(df)\n",
    "\n",
    "    X = df.drop('status_group', axis=1)\n",
    "    y = df['status_group']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, shuffle=True)\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "    print(X_train.shape)\n",
    "    print(y_train.shape)\n",
    "    print(X_test.shape)\n",
    "    print(y_test.shape)\n",
    "    y_pred = GradientBoost(X_train, X_test, y_train, y_test)\n",
    "    report = Report(y_test, y_pred)\n",
    "    print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Approach_1(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Approach_2(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Approach_3(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Approach_4(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = np.array(X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.70      0.81      0.75      6350\n",
    "           1       0.54      0.09      0.15       890\n",
    "           2       0.75      0.57      0.64      4640\n",
    "\n",
    "   micro avg       0.71      0.66      0.69     11880\n",
    "   macro avg       0.66      0.49      0.52     11880\n",
    "weighted avg       0.71      0.66      0.67     11880\n",
    " samples avg       0.66      0.66      0.66     11880"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.70      0.82      0.76      6404\n",
    "           1       0.49      0.09      0.15       844\n",
    "           2       0.77      0.52      0.63      4632\n",
    "\n",
    "   micro avg       0.72      0.65      0.68     11880\n",
    "   macro avg       0.65      0.48      0.51     11880\n",
    "weighted avg       0.71      0.65      0.66     11880\n",
    " samples avg       0.65      0.65      0.65     11880"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.72      0.82      0.77      6469\n",
    "           1       0.40      0.11      0.18       839\n",
    "           2       0.77      0.59      0.67      4572\n",
    "\n",
    "   micro avg       0.73      0.68      0.70     11880\n",
    "   macro avg       0.63      0.51      0.54     11880\n",
    "weighted avg       0.72      0.68      0.69     11880\n",
    " samples avg       0.68      0.68      0.68     11880"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c69d141fca959081254a0b2e02e55787369c1159b7ddbc81e1232bfadcd3a9e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
